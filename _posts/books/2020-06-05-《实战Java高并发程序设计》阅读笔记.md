---
layout: article
key: 072a089c-6897-44e5-8618-973cacea21e9
title: 2020-06-05-《实战Java高并发程序设计》阅读笔记
date: 2020/6/5 20:58
categories: [阅读笔记, 实战Java高并发程序设计]
tags: [阅读笔记, 实战Java高并发程序设计]
root-path: ../..
---

# 第1章 走入并行世界

## 何去何从的并行世界

## 你必须知道的几个概念

- 同步和异步

- 并发和并行

  > 并发侧重于多个任务交替运行，而多个任务之间也可能还是串行的。而并行是真正意义上的同时执行。但是，在多个CPU的场景下，并发的最终效果可能和并行是一样的。

- 临界区

- 阻塞和非阻塞

- 死锁、饥饿和活锁

  > 死锁：
  >
  > 饥饿：某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。如，线程优先级较低。
  >
  > 活锁：线程主动将资源释放给他人使用，导致资源不断的在两个线程间跳动，而没有一个线程可以同时拿到所有的资源正常执行。

## 并发级别

根据控制并发的策略，可以把并发的级别分为阻塞、无饥饿、无障碍、无锁、无等待几种。

- 阻塞

  > 可以看作是悲观策略，对于临界区的访问是阻塞的。

- 无饥饿

  > 对于非公平锁来锁，允许高优先级的线程插队，这样有可能导致低优先级的线程产生饥饿。而公平锁，就不会。

- 无障碍

  > 可以看作是乐观策略。认为对临界区的是不会发生冲突的，如果发生冲突，应该进行回滚然后阻塞执行。

- 无锁

  > 在无锁的调用中，一个典型的特点是可能会包含一个无穷循环。在这个循环中，线程会不断尝试修改共享变量。如果没有冲突，修改成功，那么程序退出，否则继续尝试修改。但无论如何，无锁的并行总能保证有一个线程可以胜出，不至于全军覆没。但是，对于竞争失败的线程，它们不断重试，直到自己获胜，如果运气不好就会出现类似饥饿的现象。

- 无等待

  > 无等待则在无锁的基础上更进一步扩展。它要求所有的线程必须在有限步内完成，这样就不会引起饥饿问题。
  >
  > 典型的无等待结构是 RCU(Read Copy Update)，基本思想是，对数据的读可以不加控制，读线程是无等待的；但是在写线程的时候，先取得原始数据的副本，接着只修改副本数据，修改完成后，在合适的时机回写数据。

## 有关并行的两个重要定律

## 回到Java：JMM

Java的内存模型（JMM）的关键技术点都是围绕着多线程的原子性、可见行以及有序性来建立的。

- 原子性

  > 一个操作是不可中断的，即使多个线程一起执行的时候，一个操作一旦开始就不会被其他线程干扰。

- 可见性

  > 指当一个线程修改了某一个共享变量的值时，其他线程是否能够立即知道这个修改。

- 有序性

  > 有序性问题的原因是程序在执行时，可能会进行指令重排，重排后的指令未必与原始指令的顺序一致。
  >
  > 指令重排的基本前提是：保证串行语义的一致性。
  >
  > 之所以需要做指令重排，就是为了尽量少地中断流水线。

# 第2章 Java并行程序基础

## 有关线程你必须知道的事

##  初始线程：线程的基本操作

## volatile 与 Java 内存模型

## 分门别类的管理：线程组

## 驻守后台：守护线程（daemon）

## 先做重要的事：线程优先级

## 线程安全的概念与关键词 synchronized

## 程序中的幽灵：隐蔽的错误

# 第三章JDK并发包

## 多线程的团队合作：同步控制

### 关键词 synchronized 的功能扩展：重入锁

ReentrantLock 重入锁可以完全替代 synchronized。但是，在JDK6.0之后，synchronzied做了大量的优化，使得两者的性能差距不大。

1. 中断响应

   对于synchronized来说，如果一个线程在等待锁，那么结果只有两种情况，要么它获得锁继续执行，要么保持等待。

   而，使用ReentrantLock，提供另外一种可能，就是线程可以被中断，即在等待锁的过程中，程序可以根据需求取消对锁的请求。`ReentrantLock#lockInterruptibly()` 这是个可以对中断进行响应的锁申请动作，即在等待锁的过程中，可以响应中断。

2. 锁申请等待限时

   `ReentrantLock#tryLock` 带参数可以限时等待锁。如果不带限时参数，则是，当前线程尝试获得锁，如果锁未被其他线程占用，则申请锁成功，并立即返回True。如果锁被其他线程占用，则当前线程不会进行等待。而是立即返回false。

3. 公平锁

   `public ReentrantLock(boolean fair)` 提供了构造函数，可以选择是否是公平锁。公平锁实现成本较高，性能较为低下，因为公平锁需要系统维护一个有序队列。

   根据系统的调度而言，一个线程会倾向于再次获取已经持有的锁。

> 对于ReentrantLock的几个重要方法，总结如下
>
> - `lock()`：获得锁，如果锁已经被占用，则等待
> - `lockInterruptibly()`：获得锁，但优先响应中断
> - `tryLock()`：尝试获得锁，如果成功，则返回true，失败返回false。该方法不等待，立即返回
> - `tryLock(long time, TimeUnit unit)`：在给定时间内尝试获得锁.
> - `unlock()`：释放锁

就重入锁的实现来看，主要集中在Java层面。在重入锁的实现中，主要包含三个要素:

- 原子状态。原子状态使用CAS操作来存储当前锁的状态，判断锁是否已经被别的线程持有了
- 等待队列。所有没有请求到锁的线程，会进入等待队列进行等待。待有线程释放锁后，系统就能从等待队列中唤醒一个线程，继续工作。
- 阻塞原语`park()`和`unpark()`，用来挂起和恢复线程。没有获得锁的线程将会被挂起。

### 重入锁的好搭档：`Condition`

Condition的作用与 wait方法和notify方法的作用大致相当。而 `Condition`是与重入锁`ReentractLock`相关联的。利用Condition对象，可以让线程在合适的时间等待，或者在某一个特定的时刻得到通知，继续执行。

与Object.wait()方法和notify()方法一样，当线程使用Condition.await()方法时，要求线程持有相关的重入锁，在Condition.await()方法调用后，这个线程会释放这把锁。同理，在Condition.signal() 方法调用时，也要求线程先获得相关的锁。在signal()方法调用后，系统会从当前Condition对象的等待队列中唤醒一个线程。一旦线程被唤醒，它会重新尝试获得与之绑定的重入锁，一旦成功获取，就可以继续执行了。因此，**在signal() 方法调用后，一般需要释放相关的锁。**

### 允许多个线程同时访问：信号量(semaphore)

信号量可以为多线程协作提供了更为强大的控制方法。

信号量是对锁的扩展。无论是内部锁 synchronized 还是重入锁 ReentrantLock，一次只允许一个线程访问一个资源，而信号量却可以指定多个线程，同时访问某一个资源。

构造信号量对象时，必须指定信号量的准入数，即同时能申请多少个许可。每个线程每次只申请一个许可时，这就相当于指定了同时有多少个线程可以访问某一个资源。

### 读写锁

`ReadWriteLock` 是JDK5中提供的读写分离锁。读写分离锁可以有效地帮助减少锁竞争，提升系统性能。

![image-20200608230409185](/assets/images/books/image-20200608230409185.png)

### 倒计数器：CountDownLatch

`CountDownLatch`是一个非常实用的多线程控制工具类。

### 循环栅栏：CyclicBarrier

`CyclicBarrier`是另外一种多线程并发控制工具。和CountDownLatch非常类似，可以实现线程间的计数等待，但是功能比CountDownLatch更加复杂和强大。

CyclicBarrier 比 CountDownLatch 略微强大一些，它可以接受一个参数作为 BarrierAction，即当计数器一次计数完成后，系统会执行的动作，如下构造函数，

```java
public CyclicBarrier(int parties, Runnable barrierAction) // parties 计数总数，barrierAction 执行动作
```

在 CyclicBarrier 等待的过程中，BrokenBarrierException 是其特有异常。一旦遇到此异常，则表示当前的 CyclicBarrier已经破损，可能系统已经无法等待所有的线程到齐了。

### 线程阻塞工具类：LockSupport

LockSupport 是一个非常方便实用的线程阻塞工具：可以在线程内任意位置让线程阻塞。

> 和 `Thread.suspend()` 方法相比，弥补了由于 `resume()` 方法发生导致线程无法继续执行的情况
>
> 和`Object.wait()`方法相比，不需要先获得某个对象的锁，也不会抛出 interruptException异常。

LockSupport使用了类似信号量的机制。它为每一个线程准备了一个许可，如果许可可用，那么 park() 方法会立即返回，并且消费这个许可(也就是将许可变为不可用)，如果许可不可用，就会阻塞，而 unpark() 方法则就是让一个许可变为可用(但是和信号量不同的是，许可不能累加，你不可能拥有超过一个许可，它永远只有一个)。

![image-20200608234606982](/Users/shushu/Library/Application Support/typora-user-images/image-20200608234606982.png)

除了有定时阻塞的功能以外，LockSupport.park() 方法还能支持中断影响。但是和其他接收中断的函数不一样，LockSupport.park() 方法不会抛出 InterruptedException 异常，只会默默返回，但是可以从 Thread.interrupted() 等方法中获得中断标记。

### Guava 和 RateLimiter 限流

这里将介绍 Guava中提供的一款限流工具 RateLimiter，RateLimiter是一款限流工具。

一般化的限流算法有两种：漏桶算法和令牌桶算法。

> - 漏桶算法
>
>   利用一个缓冲区，当有请求进入系统时，无论请求的速率如何，都先在缓存区保存，然后以固定的流速流出缓存区进行处理。
>
>   其特点是：无论外部请求压力如何，漏桶算法总是以固定的流速处理数据。漏桶的容积和流出速率是该算法的两个重要参数。
>
> - 令牌桶算法
>
>   是一种反向的漏桶算法。在令牌桶中存放的不再是请求，而是令牌。处理请求只有拿到令牌后，才能对请求进行处理。如果没有令牌，那么处理程序要么丢弃请求，那么等待可用的令牌。为了限制流速，该算法在每个单位时间产生一定量的令牌存入桶中。
>
>   通常，桶的容量是有限的，当令牌没有被消耗时，只能累积有限单位时间内的令牌数量。

RateLimiter采用了令牌桶算法，但是不保证公平(that it does not guarantee fairness)。

- `acquire()`：阻塞
- `tryAcquire()`：未拿到许可会丢弃请求，注意是判断返回值。



## 线程复用：线程池

控制和管理多线程的原因

- 创建和管理线程需要花费时间
- 线程本身需要占用内存，大量的线程回收会给GC带来很大压力。

### 什么是线程池

### 不要重新发明轮子：JDK对线程池的支持

JDK提供了一套Executor框架，可以有效进行线程控制，其本质就是一个线程池。

Executors 工厂类提供了一系列方便的方法

- newFixedThreadPool()

  该方法返回一个固定线程数量的线程池。**注意：其使用了无界任务队列，当任务提交非常频繁的时候，该队列可以迅速，从而耗尽系统资源**

- newSingleThreadExecutor()

  只是简单将 newFixedThreadPool() 线程池线程数量设置为1。**所以还是存在风险**

- newCachedThreadPool()

  corePoolSize 为0，maximumPoolSize 无穷大的线程池，在没有任务时，该线程池无线程。

  若无空闲线程，则将任务加入 SynchronousQueue队列，而 SynchronousQueue作为一种直接提交的队列，总是迫使线程池增加新的线程执行任务。**所以还是存在风险**

- newSingleThreadScheduledExecutor()

- newScheduledThreadPool()：该方法返回一个ScheduledExecutorService对象，但是线程池可以指定线程的数量。

这里newScheduledThreadPool() 返回的对象可以根据时间需要对线程进行调度，和其他几个线程池不同，ScheduledExecutorService并不一定会立即安排执行任务，起到是计划任务的作用，会在指定的时间，对任务进行调度。其内部方法 scheduleAtFixedRate() 和 scheduleWithFixedDelay() 会对任务进行周期性的调度，但是有点区别

- scheduleAtFixedRate：任务调度的频率是一定的。以上一个任务开始执行时间为起点，在之后的period时间调度下一次任务。

  > Creates and executes a periodic action that becomes enabled first after the given initial delay, and subsequently with the given period; that is executions will commence after initialDelay then initialDelay+period, then initialDelay + 2 * period, and so on. If any execution of the task encounters an exception, subsequent executions are suppressed. Otherwise, the task will only terminate via cancellation or termination of the executor. If any execution of this task takes longer than its period, then subsequent executions may start late, but will not concurrently execute.

- scheduleWithFixedDelay：是以上一个任务结束后，在经过delay时间进行任务调度。

  > Creates and executes a periodic action that becomes enabled first after the given initial delay, and subsequently with the given delay between the termination of one execution and the commencement of the next. If any execution of the task encounters an exception, subsequent executions are suppressed. Otherwise, the task will only terminate via cancellation or termination of the executor.

**注意：如果任务遇到异常，那么后续所有子任务都会停止调度，因此，必须保证异常被及时处理，为周期性任务的稳定调度提供条件**

**另外：使用完线程池后，记得关闭线程池**

### 刨根问底：核心线程池的内部实现

对于newFixedThreadPool()/newSingleThreadExecutor()/newCachedThreadPool() 方法来说，内部实现均使用了 ThreadPoolExecutor类。

该类的构造函数：

```java
    /**
     * Creates a new {@code ThreadPoolExecutor} with the given initial
     * parameters.
     *
     * @param corePoolSize the number of threads to keep in the pool, even
     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set
     * @param maximumPoolSize the maximum number of threads to allow in the
     *        pool
     * @param keepAliveTime when the number of threads is greater than
     *        the core, this is the maximum time that excess idle threads
     *        will wait for new tasks before terminating.
     * @param unit the time unit for the {@code keepAliveTime} argument
     * @param workQueue the queue to use for holding tasks before they are
     *        executed.  This queue will hold only the {@code Runnable}
     *        tasks submitted by the {@code execute} method.
     * @param threadFactory the factory to use when the executor
     *        creates a new thread
     * @param handler the handler to use when execution is blocked
     *        because the thread bounds and queue capacities are reached
     * @throws IllegalArgumentException if one of the following holds:<br>
     *         {@code corePoolSize < 0}<br>
     *         {@code keepAliveTime < 0}<br>
     *         {@code maximumPoolSize <= 0}<br>
     *         {@code maximumPoolSize < corePoolSize}
     * @throws NullPointerException if {@code workQueue}
     *         or {@code threadFactory} or {@code handler} is null
     */
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.acc = System.getSecurityManager() == null ?
                null :
                AccessController.getContext();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

```

- corePoolSize：指定了线程池中的核心线程数量
- maximumPoolSize：指定了线程池中的最大线程数量
- keepAliveTime：当线程池数量超过了 corePoolSize 时，多余的空闲线程的存活时间，即超过了 corePoolSize的空闲线程，在多长时间内会被销毁
- unit：keepAliveTime的单位
- workQueue：任务队列，被提交但尚未被执行的任务
- threadFactory：线程工厂，用于创建线程，一般用默认的即可
- hadlder：拒绝策略。

重点说明，workQueue和handler两个参数

- workQueue

  指被提交但未执行的任务队列，仅用于存放 Runnable对象，根据功能分类，使用以下几种BlockingQueue接口

  - 直接提交的队列：SynchronousQueue

    SynchronousQueue是一个特殊的BlockingQueue，**其没有容量**，每一个插入操作都要等待一个相应的删除操作，反之每个删除操作都需要等待相应的插入操作。

    如果使用SynchronousQueue，则提交的任务不会真实的保存，而总是将新任务提交给线程执行，如果没有空闲的线程则创建新的线程，如果到达最大线程则执行拒绝策略。

  - 有界的任务队列：ArrayBlockingQueue

    ArrayBlockingQueue类的构造函数必须带一个容量参数，表示该队列的最大容量。

    线程池的实际线程数小于corePoolSize，则优先创建新的线程；

    若大于corePoolSize，则加入等待队列；

    若等待队列已满，无法加入，则总线程数不大于maximumPoolSize的前提， 创建新的进程执行任务；

    若大于maximumPoolSize则执行拒绝策略。

  - 无界的任务队列：LinkedBlockingQueue

    与有界任务队列相比，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况。

    当有新任务的时候，系统的线程数小于corePoolSize时，线程池会生成新的线程；达到corePoolSize，就不会继续增加了，任务直接进入到队列等待，一直增加，直至耗尽系统内存。

  - 优先任务队列：PriorityBlockingQueue

    优先任务队列是带有执行优先级的队列；

    特殊的无界队列，可以根据任务自身的优先级顺序先后执行。

ThreadPoolExecutor 线程池的核心调度代码

>```java
>public void execute(Runnable command) {
>    if (command == null)
>        throw new NullPointerException();
>    /*
>     * Proceed in 3 steps:
>     *
>     * 1. If fewer than corePoolSize threads are running, try to
>     * start a new thread with the given command as its first
>     * task.  The call to addWorker atomically checks runState and
>     * workerCount, and so prevents false alarms that would add
>     * threads when it shouldn't, by returning false.
>     *
>     * 2. If a task can be successfully queued, then we still need
>     * to double-check whether we should have added a thread
>     * (because existing ones died since last checking) or that
>     * the pool shut down since entry into this method. So we
>     * recheck state and if necessary roll back the enqueuing if
>     * stopped, or start a new thread if there are none.
>     *
>     * 3. If we cannot queue task, then we try to add a new
>     * thread.  If it fails, we know we are shut down or saturated
>     * and so reject the task.
>     */
>    int c = ctl.get();
>  	// 当前线程池的线程总数
>    if (workerCountOf(c) < corePoolSize) {
>        if (addWorker(command, true))
>            return;
>        c = ctl.get();
>    }
>    if (isRunning(c) && workQueue.offer(command)) {
>        int recheck = ctl.get();
>        if (! isRunning(recheck) && remove(command))
>            reject(command);
>        else if (workerCountOf(recheck) == 0)
>            addWorker(null, false);
>    }
>    else if (!addWorker(command, false))
>        reject(command);
>}
>```

### 超负载了怎么办：拒绝策略

JDK内置了四种拒绝策略

- AbortPolicy

  该策略会直接抛出异常，阻止系统正常工作

- CallerRunsPolicy

  只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。

- DiscardOldestPolicy

  该策略将丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。

- DiscardPolicy

  该策略默默地丢弃无法处理的任务，不予任何处理。**如果允许任务丢失，这个是推荐的策略**。

以上内置策略均实现了 RejectedExecutionHandler接口，如果以上无法满足实际应用的需要，可以自己扩展实现。

### 自定义线程创建：ThreadFactory

ThreadFactory是一个接口，只有一个方法用来创建线程。

```java
Thread newThread(Runnable r);
```

使用自定义 ThreadFactory，可以跟踪线程池究竟在何时创建了多少线程，也可以自定义线程的名称、组以及优先级等信息。甚至可以任性的将所有线程设置为守护线程。

比如：如果将所有线程都设置为守护线程，这样当主线程退出后，就会强制销毁线程池。

### 我的应用我做主：扩展线程池

可以对ThreadPoolExecutor进行扩展来，监控每个任务执行的开始时间和结束时间，或者一些其他功能。

ThreadPoolExecutor提供了三个接口来对线程池进行控制。

```java
// 任务执行前
protected void beforeExecute(Thread t, Runnable r) { }

// 任务执行后
protected void afterExecute(Runnable r, Throwable t) { }

// 线程池销毁时
protected void terminated() { }
```

### 合理的选择：优化线程池线程数量

在Java中可以通过下面获取可用的Cpu数量

```java
Runtime.getRuntime().availableProcessors()
```

一半啊，线程池大小需要考虑CPU数量、内存大小等因素。《Java Concurrency in Practice》一书给出的估算公式
$$
N_{threads} = N_{cpu} \times U_{cpu} \times (1 + W/C)
$$
其中，$U_{cpu}$ 是目标CPU的使用率，$W/C$ 表示等待时间与计算时间的比率。

### 堆栈去哪里了：在线程池中选择堆栈

线程池存在一些"坑"，比如线程池很可能会 "吃掉" 程序抛出的异常，导致我们的程序的错误一无所知。

获取线程池异常堆栈的方法

1. 放弃 submit() 方法而改用 execute() 方法

   `pools.execute(...)`

   ```shell
   Exception in thread "pool-1-thread-1" java.util.concurrent.ExecutionException: java.lang.ArithmeticException: / by zero
   	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
   	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
   	at com.coding.jdk.multithreading.lock.ReentrantLockDemo.ThreadPoolExecutorDemo.main(ThreadPoolExecutorDemo.java:43)
   Caused by: java.lang.ArithmeticException: / by zero
   ```

2. 改造submit() 方法

   ```java
   Future re = pools.submit(...)；
   re.get();
   ```



上述方法获得得到的是**部分堆栈信息**。之所以是部分，是因为从这两个堆栈中，我们只能知道异常是在那里抛出的，但是我们还是希望得到更重的信息，那就是这个任务是在那里提交的？而任务的具体提交位置已经被线程池完全淹没了，顺着堆栈，我们最多只能找到线程池中的调度流程，而这对于我们几乎是没有价值的。

所以，第3种方法是，扩展ThreadPoolExecutor线程池，让它在调度任务前，先保存一下提交任务线程的堆栈信息。

3. 扩展ThreadPoolExecutor

   相比于前两个方法，好处是能够知道这个异常的Task是在那里提交的。

   ```java
   package com.coding.jdk.multithreading.lock.ReentrantLockDemo;
   
   import java.util.concurrent.BlockingQueue;
   import java.util.concurrent.Future;
   import java.util.concurrent.SynchronousQueue;
   import java.util.concurrent.ThreadPoolExecutor;
   import java.util.concurrent.TimeUnit;
   
   /** @Author shu wj @Date 2020/6/13 15:25 @Description */
   public class TraceThreadPoolExecutor extends ThreadPoolExecutor {
     public TraceThreadPoolExecutor(
         int corePoolSize,
         int maximumPoolSize,
         long keepAliveTime,
         TimeUnit unit,
         BlockingQueue<Runnable> workQueue) {
       super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);
     }
   
     @Override
     public void execute(Runnable command) {
       super.execute(wrap(command, clientTrace(), Thread.currentThread().getName()));
     }
   
     @Override
     public Future<?> submit(Runnable task) {
       return super.submit(wrap(task, clientTrace(), Thread.currentThread().getName()));
     }
   
     private Exception clientTrace() {
       return new Exception("client stack trace");
     }
   
     private Runnable wrap(final Runnable task, final Exception clientStack, String clientThreadName) {
       return new Runnable() {
         @Override
         public void run() {
           try {
             task.run();
           } catch (Exception e) {
             clientStack.printStackTrace();
             throw e;
           }
         }
       };
     }
   
     public static void main(String[] args) {
        ThreadPoolExecutor threadPoolExecutor = new TraceThreadPoolExecutor(0, Integer.MAX_VALUE, 0L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
   
        for (int i = 0; i < 1; i++) {
          threadPoolExecutor.execute(new ThreadPoolExecutorDemo.Task(1, 0));
        }
     }
   }
   
   ```

   ```shell
   java.lang.Exception: client stack trace
   	at com.coding.jdk.multithreading.lock.ReentrantLockDemo.TraceThreadPoolExecutor.clientTrace(TraceThreadPoolExecutor.java:31)
   	at com.coding.jdk.multithreading.lock.ReentrantLockDemo.TraceThreadPoolExecutor.execute(TraceThreadPoolExecutor.java:22)
   	at com.coding.jdk.multithreading.lock.ReentrantLockDemo.TraceThreadPoolExecutor.main(TraceThreadPoolExecutor.java:52)
   Exception in thread "pool-1-thread-1" java.lang.ArithmeticException: / by zero
   	at com.coding.jdk.multithreading.lock.ReentrantLockDemo.ThreadPoolExecutorDemo$Task.run(ThreadPoolExecutorDemo.java:25)
   	at com.coding.jdk.multithreading.lock.ReentrantLockDemo.TraceThreadPoolExecutor$1.run(TraceThreadPoolExecutor.java:39)
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
   	at java.lang.Thread.run(Thread.java:748)
   ```

### 分而治之：Fork/Join框架

![image-20200613153721242](/assets/images/books/image-20200613153721242.png)

JDK中，提供了一个ForkJoinPool线程池，对于fork() 方法并不急于开启线程，而是提交给ForkJoinPool线程池进行处理。

- 由于线程池的优化，提交的任务和线程数量并不是一一对应的关系。
- 一个物理线程实际上需要处理多个逻辑任务，因此每个线程必然拥有一个任务队列
- 当一个线程试图“帮助”其他线程时，总是从任务队列的底部开始获取数据，而线程试图执行自己的任务时，则是从相反的顶部开始获取数据。
- 如果任务的层次很多，一直得不到返回，那么可能出现两种情况：第一，系统内的线程数量越积越多，导致性能严重下降；第二，函数的调用层次变多，最终导致栈溢出。



> 额外：`@sun.misc.Contended` 这个注解，据说是为了避免伪共享。
>
> ```
> @sun.misc.Contended
> public class ForkJoinPool extends AbstractExecutorService
> ```

### Guava中对线程池的扩展

1. 特殊的DirectExecutor线程池

   DirectExecutor线程池很简单，它并没有真的创建或者使用额外的线程，它总是将任务放在当前线程中直接执行。

   为什么需要这样一个线程池？**软件设计的需要**。

   > 从软件设计的角度来说，抽象是软件设计的根本和精髓。将不同业务的共同属性提取并抽取成模型非常有利于对不同业务的统一处理。

   对于线程池来说，其技术目的是为了复用线程池以提高运行效率，但其业务需求却是异步执行一段业务指令。但有的时候，异步并不是必要的。任何一个可以运行Runable的实例的模块都可以视为线程池，即使它没有真正的创建线程，这样就把同步和异步执行进行统一，使用统一的编码风格来处理同步和异步调用，进而简化设计。

2. Daemon线程池

   提供了将普通线程池，转化为Daemon线程池的方法。在很多场合，我们并不希望后台线程池阻止程序的退出，当系统完成后，即便线程池存在，依然希望进程结束执行。

   `MoreExecutors.getExitingExecutorService()`

3. 对Future模式的扩展

   `TODO:待后续完善 `



## 不要重复发明轮子：JDK的并发容器

### 超好用的工具类：并发集合简介

先简单介绍一下

- ConcurrentHashMap

  高效的并发hashMap。

- CopyOnWriteArrayList

  在读多写少的情况下，这个List的性能非常好，远高于Vector

- ConrurrentLinkedQueue

  高效的并发队列，可以看作一个线程安全的LinkedList

- BlockingQueue

  阻塞队列，适合作为数据共享的通道

- ConrurrentSkipListMap

  跳表的实现，这是一个Map，使用跳表的数据结构进行快速查找。

除了上述并发包里的专有数据结构外，java.util 下的Vector是线程安全的（虽然性能和上述专用工具没法比），另外 Collections 工具类可以帮助我们将任意集合包装为线程安全的集合。

### 线程安全的HashMap

- Collections.synchronizedMap() 来包装HashMap
- ConcurrentHashMap

ConcurrentHashMap专门进行了性能优化，更及时适合多线程的场合。

### 有关List的线程安全

- Collections.synchronizedList() 可以用来包装任意的List
- 并发包里实现的List

### 高效读写的队列：深度剖析ConrurrentLinkedQueue类

ConcurrentLinkedQueue可以算做是在高并发环境中性能最好的队列了。

`TODO:内部详细实现学习 `

### 高效读取：不变模式下的CopyOnWriteArrayList类

特点是：读取是完全不用加锁的，写入也不会阻塞读取操作，只有写入和写入之间需要进行同步等待。

原理：在写入的时候自我复制，即当这个List需要修改时，并不修改原来的内容，而是对原有的数据进行一次复制，将修改的内容，写入副本中，然后再用修改后的副本替换原来的数据，这样就保证写操作不会影响读了。

### 数据共享通道：BlockingQueue

BlockingQueue之所以适合作为数据共享的共享的通道，在于Blocking阻塞。其次，Blocking会让服务线程在队列为空时进行等待，当有新的消息进入队列后，自动将线程唤醒。

### 随机数据结构：跳表（SkipList）

跳表是一种可以用来快速查找的数据结构，有点类似于平衡树，可以对元素进行快速查找。有一个重要的区别是，对平衡树的插入和删除往往可能导致平衡树进行一次全局的调整，而对调表的插入和删除只需要对整个数据结构的局部进行调整即可。这样的好处是：在高并发的情况下，需要一个全局锁来保证整个平衡树的线程安全，而对于跳表来说，只需要部分锁即可。

查询性能，跳表的时间复杂读是 $O(log n)$

跳表的另一个特点是随机算法。跳表的本质是同时维护了多个链表，同时链表是分层的。【插入是随机的，如果运气不好可能得到一个性能糟糕的结构，但是在实际使用中一般是表现是很好的】

跳表是空间换取时间的算法。

跳表实现Map和使用哈希算法实现map的不同之处是，哈希不会保持元素的顺序，而跳表里的元素都是有序的。

`TODO:学习内部实现`

## 使用JMH进行性能测试

### 什么是JMH

JMH（Java Microbenchmark Harness）是一个在OpenJDK项目中发布的，专门用于性能测试的框架，精度可以到达毫秒级。通过JMH可以对多个方法的性能进行量化分析。

### Hello JMH

### JMH的基本概念和配置

1. 模式 Mode

   - Throughout：整体吞吐量，表示1秒内可以调用多少次
   - AverageTime：调用平均时间，指每一次调用所需的时间
   - SampleTime：随机取样，最后输出取样结果的分析。例如："99%的调用在xxx毫秒以内..."
   - SingleShotTime：以上模式都是默认一次Iteration是1秒，唯有SingleShotTime只运行一次。往往同时把warmup此时设置为0，用于测试冷启动时的性能

2. 迭代 Iteration

   迭代时JMH的一次策略单位。大部分测试模式下，一次迭代表示1秒，在这一秒内会不间断的调用被测试方法，并采用计算吞吐量、平均时间等。

3. 预热 Warmup

   由于Java虚拟机的JIT的存在，同一个方法在JIT编译前后的时间将会不同，通常考虑方法在JIT之后的性能

4. 状态 State

   通过State可以指定一个对象的作用范围，范围主要有两种

   一种是线程范围，也就是一个线程只会被一个线程访问

   另一种是基础测试范围，即多个线程共享一个实例

5. 配置类 Options/OptionsBuilder

   在测试开始前需要指定一些参数，比如测试类（include）、使用进程个数（fork）、预热迭代次数（warmupIterations）。

### 理解JMH的Mode

### 理解JMH的State

### 有关性能的思考

### CopyOnWriteArrayList 和 ConcurrentLinedQueue 类

CopyOnWriteArrayList：通过写复制来提高性能

ConcurrentLinedQueue：通过CAS操作和锁分离来提高系统性能。

**当元素总量不大时，在绝大部分场景下，CopyOnWriteArrayList 要优于 ConcurrentLinedQueue。** 在并发场景下，复制的消耗相对较少。



# 第4章 锁的优化和注意事项

> 对于单任务或者单线程的应用而言，主要资源消耗花在任务本身。
>
> 对于多线程应用来说，系统除了处理功能需求以外，还需要额外维护多线程环境的特有信息，如线程本身的元数据、线程调度、线程上下文的切换等。

## 有助于提高锁性能的建议

> 锁的竞争必然会导致程序的整体性能下降。

### 减少锁持有的时间

只有在必要时进行同步，可以明显减少线程持有锁的时间，提高系统的吞吐量。

减少锁的持有时间有助于降低锁冲突的可能性，进而提高系统的并发能力。

### 减小锁粒度

所谓减小锁粒度，就是指缩小锁定对象的范围，从而降低锁冲突的可能性，进而提高系统的并发能力。

典型的使用场景是，ConcurrentHashMap类的实现。

### 用读写分离锁来替换独占锁

在读多写少的场景下，读写锁可以有效提升系统的并发能力。

### 锁分离

锁分离是 读写锁思想的进一步延伸。

读写锁根据读写操作功能上的不同，进行了有效的锁分离。依据应用程序的功能特点，使用类似的分离思想，也可以对独占锁进行分离。典型的案例是 `LinkedBlockingQueue`，其take() 和 put() 方法分别实现了从队列中取得数据和往队列中增加数据的功能，虽然两个方法都对当前队列进行了操作，但由于基于链表的，因此两个操作分别作用于队列的前端和尾端，从理论上来说，两者并不冲突。

### 锁粗化

通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能的短，使用完公共资源后，应该立即释放锁。但是，如果频繁对同一个锁不停的进行请求，同步和释放，其本身也会消耗资源，反而不利于性能的优化。

> 虚拟机在遇到一连串连续地对同一个锁不断进行请求和释放的操作时，便会把所有的锁操作，整理对锁的一次请求，从而减少对锁的请求同步的次数，这个操作叫做锁的粗化。

开发过程中，也有必要有意识的在合理的场合进行锁的粗化。

## Java虚拟机对锁优化所做的努力

### 锁偏向

### 轻量级锁

### 自旋锁

### 锁消除

Java虚拟机在JIT编译时，通过运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间。

锁消除涉及到一项关键技术为逃逸技术。

> 逃逸技术：观察某一个变量是否会逃出某个作用域。以此为基础，虚拟机才可以，将变量从内部消除。
>
> 逃逸分析必须在 -server模式下进行，可以使用 `-XX:+DoEscapeAnalysis` 参数打开逃逸分析，使用 `-XX:+EliminateLocks` 参数打开锁消除。

## 人手一只笔：ThreadLocal

除了控制资源的访问外，还可以通过增加资源来保证所有对象的线程安全。

### TreadLocal的简单使用

ThreadLocal是一个局部变量，只有当前线程可以访问，所以是线程安全的。

### ThreadLocal的实现原理

TODO。

### 对性能有何帮助

为每个线程分配一个独立的对象对系统性能也许有帮助的。当然了，这也不一定，完全取决于共享对象的内部逻辑。如果共享对象对于竞争的处理容易引起性能损失，那应该考虑使用ThreadLocal为每个线程分配单独的对象。

典型的案例就是在多线程下产生随机数。

## 无锁

锁是一种悲观的策略。无锁的策略使用一种叫作比较交换(CAS)的技术来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作直到没有冲突为止。

### 与众不同的并发策略：比较交换

与锁相比，使用比较交换会使程序看起来更加复杂一些，但由于其非阻塞性，它对死锁问题天生免疫，并且线程间的相互影响也远远比基于锁的方式要小。更为重要的是，使用无锁的方式**完全没有锁竞争带来的系统开销**，也**没有线程间频繁调度带来的开销**，因此，它要比基于锁的方式拥有更优越的性能。

### 无锁的线程安全整数：AtomicInteger

JDK并发包中有一个atomic包，里面实现了一些直接使用CAS操作的线程安全的类型。

### Java中的指针：Unsafe类

`sun.misc.Unsafe` 类型，里面封装了一些不安全的操作。不安全的原因是：指针是不安全的，如果指针指错了位置，或者计算指针偏移量时出错，结果可能是灾难性的，你很可能会覆盖别人的内存，导致系统崩溃。

Unsafe 类就是封装了一些类似指针的操作。

JDK的开发人员并不希望大家使用这个类。或者Unsafe类实例的方法是调动其工厂方法 getUnsafe()，其实现是

```java

  public static Unsafe getUnsafe() {
    Class cc = Reflection.getCallerClass();
    if (cc.getClassLoader() != null) {
      throw new SecurityException("Unsafe");
    } else {
      return theUnsafe;
    }
  }
```

这里会检查调用 getUnsafe() 函数的类，如果这个类的 ClassLoader 不为null，就直接抛出异常，拒绝工作。因此，这也使得我们自己的应用程序无法直接使用Unsafe类，它是个JKD内部使用的专属类。

> 根据Java类加载其的工作原理，应用程序的类由AppLoader加载，而系统核心类，如rt.jar 中的类由Bootstrap类加载器加载。Bootstrap类加载器没有Java对象的对象，因此试图获得这个类加载器会返回null，所以当一个类加载器为null时，说明是由Bootstrap类加载器加载的。

### 无锁的对象引用：AtomicReference

AtomicReference 和 AtomicInteger 非常类似，不同之处在于 AtomicInteger 是对整数的封装，而 AtomicReference 则是对应普通的对象引用。也就是它可以保证你在修改对象引用时的线程安全性。

> 原子操作逻辑上的不足：
>
> 就是当获得对象当前数据后，在准备修改为新值时，对象的值被其他线程连续修改了两次，而经过这两次修改后，对象的值又恢复为旧值。这样，当前线程就无法正确判断这个对象究竟是否被修改过。

因此，如果在下面这种场景下，AtomicReference就不再适用了。就是我们是否能够修改对象的值，不仅取决于当前值，还和对象的过程变化有关。

JDK考虑到了这种情况，提供了AtomicStampedReference。

### 带有时间戳的对象引用：AtomicStampedReference

AtomicReference 无法解决上述问题的根本原因是，对象在修改过程中丢失状态信息，对象值本身与状态被画上了等号。因此，只要能够记录对象在修改过程中的状态值，就可以很好地解决对象被反复修改导致线程无法正确判断对象状态的问题。

AtomicStampedReference 内部不仅维护了对象值，还维护了一个时间戳（实际上可以是任意的一个整数来表示状态值）。当 AtomicStampedReference 设置对象值时，对象值及时间戳都必须满足期望值，写入才会成功。

### 数组也能无锁：AtomicIntegerArray

当前可用的原子数组有：AtomicIntegerArray，AtomicLongArray 和 AtomicReferenceArray，分别表示整数数组、long型数组和普通的对象数组。

### 让普通变量也享受原子操作：AtomicIntegerFieldUpdater